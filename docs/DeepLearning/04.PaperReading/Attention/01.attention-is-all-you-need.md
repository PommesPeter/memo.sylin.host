---
title: Attention is All You Need
tags:
  - Attention
---

# Attention is All You Need

## Abstract

现在主流的序列翻译模型都是基于循环神经网络或者卷积神经网络来做的，也就是包含了 encoder 和 decoder。现阶段最好的模型也是通过注意力机制将 encoder 和 decoder 连接起来。所以我们提出了一种仅用注意力机制的简单结构，完全不使用 CNN 和 RNN。我们的架构在其他领域也非常适用。

## Introduction



## Conclusion

第一个仅用注意力机制实现序列转换模型，将 encoder-decoder 架构中的循环层替换成多头自注意力。对于翻译任务 Transformer 的训练速度也比循环层或卷积层快。

我们的模型可以应用其他任务上，在任何基于 attention 的模型都是适用的。Transformer 可以应对不同的数据类型的输入都是适用的，例如图像、音频、视频。