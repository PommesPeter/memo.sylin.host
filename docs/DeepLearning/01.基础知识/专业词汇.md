---
title: 专业词汇记录
tags:
  - 神经网络
---

# 词汇记录 (Vocab)

## SGG

- long-tail problem
  在实际的视觉相关问题中，数据都存在长尾分布：少量类别占据绝大多数样本，大量的类别仅有少量的样本，比如 open-images,ImageNet 等。[Long-Tail(长尾)问题的解决方案](https://blog.csdn.net/qq_36523203/article/details/107019526)
- head/tail categories
  指的是数据的分布，head 表示数量较多的那一堆类别，tail 表示数量较少的那一堆类别。
- bias
  指的是某种偏差，有偏差的 sth。e.g. biased prediction, biased distribution

## Classification

- intra-class
  类别内的特征之间的区别，以人脸举例，同一个人不同状态下脸的特征之间的差异
- inter-class
  类别间的特征之间的区别，以人脸举例，不同人的人脸特征之间的差异

```ad-note
对于人脸识别任务来说，肯定是希望inter-class很大，intra-class很小，这样我们的模型才能更好的识别不同的类
```

- logits
  表示的是神经网络最后一层输出的内容，一般是全连接层的输出。一般也会将 logits 用于 softmax 得到最后的概率。

## Unsupervied Learning

- hypothesis space
- Zeroshot Learning
  详情请见 [[2022-11-09-21-47-11-Zero_Shot_Learning]]
- Emergent zero-shot
  与 zero-shot 的区别在于方法的训练方式。像 CLIP [59]、AudioCLIP [26]等方法是通过模态配对（图像，文本）和（音频，文本）进行训练，以展示使用文本提示进行同一模态的零样本分类。相反，IMAGEBIND仅使用图像配对数据将模态绑定在一起。因此，仅通过在（图像，文本）和（图像，音频）上进行训练，IMAGEBIND可以使用文本提示进行音频的零样本分类。由于我们并没有直接训练这种能力，我们将其称为Emergent zero-shot分类，以区别于那些针对所有模态特定训练的方法，这些方法使用了配对的文本监督。
- Inductive Learning
  1. 根据已有的数据归纳出已有数据共通的模式，应用新的数据或任务（从特定场景到一般场景）。训练模型过程中只有训练集对模型可见，测试集对模型不可见，目的是使得模型具有通用性和泛化性。
  2. 在一个域上学习，模型可以根据训练集学习到的 pattern 应对未知的数据。（特定场景 --> 一般场景）
  3. 只管 training set，只关注于应对 test data
  4. 复用性较好，新数据不需要重新训练
  5. 计算量小，但效果不确定
  6. 对应 Meta Learning 要求从诸多给定的任务和数据中学习通用的模式，迁移到未知的任务和数据上。
- Transdutive Learning
  1. 当前学习的知识能够直接应用到新的数据或任务（从特定场景到特定场景）。训练模型过程中训练集（带标签）和测试集（不带标签）都对模型可见，除测试集标签以外的所有信息都对模型可见，所以可以利用额外的信息给模型带来增益。
  2. 在同一个域上学习，一个模型只能应对同一个域上学习的数据。（特定场景 --> 特定场景）
  3. 不管 test set，只关注于应对 unseen data
  4. 复用性较差，新数据加入需要重新训练
  5. 计算量较大，但效果好
  6. 对应 Domain Adaptation 给定训练的数据包含了目标域数据，要求训练一个对目标域数据有最小误差的模型。
- out-of-distribution
  预测训练数据以外的数据，叫做 OOD 数据。将训练好的模型部署应用的时候，尝试 预测当前画面上没出现过的东西，叫做 OOD 检测。
- Imbalanced Learning
  一种应对 Long-tailed 问题的学习任务，以保持少数类别的多样性和平衡预测。
- Few-shot
  - Meta-Learning
    1. metric-based
    2. optimization-based
- Agnostic
  指某样事物是不可见的，不是针对特定的某个事物。（与 specific 是反义词）
  e.g. 第一个阶段不涉及任何下游任务，就是拿着一堆无标签的数据去预训练，没有特定的任务，这个话用官方语言表达叫做：**in a task-agnostic way**。第二个阶段涉及下游任务，就是拿着一堆带标签的数据去在下游任务上 Fine-tune，这个话用官方语言表达叫做：**in a task-specific way**。

## Domain Adaptation

- Label
  所谓的 label 就是我们在进行网络训练时候的**监督信息**，比如在分类任务中就是一个个 one-hot 编码。
- Soft Label
  比如相比人来说，猫和狗的共同之处还是蛮多的，也就是在预测一张“狗图”的时候，可能会产生“0.09-0.9-0.01”这个结果的，这个“0.09-0.9”与“0.9-0.01”其实是不同的，这说明“猫狗”之间的近似度可能是远大于“狗人”的。这个“0.09-0.9-0.01”其实就包含了一定的类别关系，故这种表示形式就是**软标签**（soft label）。
- Hard Label
  比如猫狗人三分类任务中，我们可以用 “001” 表示猫，“010” 表示狗，“100” 表示人。当然了，这种 one-hot 标签显然就是**硬标签**（hard label），因为它无法反映类别之间的关系。
- [[2022-11-28-22-01-99-Domain_Adaptation]]

## Multi-Modal

- Grounding
  1. 将语言和视觉两种模态进行对齐和融合，使得模型能够理解语言中指定的目标物体，并将其定位在图像中。（不同模态的结合）
  2. 利用大量的图像-文本对数据来学习视觉表示，而不需要额外的对象类别标注。这使得模型能够覆盖更多的视觉概念，并提高了模型在不同任务和领域上的迁移能力。在视觉任务中利用 text/phrase 等信息作为特征一起使用。
  3. 可以理解为将 image 中的 region 对应到地面上的 phrase。
  4. 将对应 text 的描述从 image 上进行匹配（UniIVAL）
- Grounding Task
  可以理解为将本来单模态的任务转换成多个模态融合的任务。
- Visual Grounding
  根据指令检测符合 text 描述的 image 上的物体。也就是按照 text 的要求匹配 image 上的物体。

## Others

- Online Learning
  训练过程中一次只能看到一部分数据，根据当前状态动态调整，数据以流式的方式进行更新。（类似于边训练边更新训练数据）
  第一次输入是数据 A，第二次输入是数据 B，....
- Offline Learning
  一次看到所有的数据，先学习所有情况再根据情况做判断。（直接训练）
- Consistency Check
  一致性检查是为确定数据是否存在任何内部冲突而执行的测试。更具体地说，为数据编写的规则是否有矛盾的陈述。
- Proxy Task
  代理任务，指将预训练好的模型用在其他的下游任务，用来反映模型的性能。

## 未归类

- 自回归（auto-regressive）
  第 $i$ 个位置的预测结果是根据前 $i-1$ 特征或者预测结果来决定的。
- Inductive Bias
  归纳（Induction）指的是我们从例子中发现共性的能力，而 Bias 即偏差，两个词连在一起就是我们总结某一类事物的时候，出现了偏差，不能反映事物的真实全貌。**普遍存在的刻板印象**就是[归纳偏差](https://www.zhihu.com/search?q=%E5%BD%92%E7%BA%B3%E5%81%8F%E5%B7%AE&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2021534291%7D)的一个最好现实例子。
  ![[Pasted image 20230922170036.png]]
  - 我们原来认识的太少了，并不是真正的了解真实的世界（数据和真实分布不同导致的偏差，或者说数据量太少）；
  - 我们原来归纳的方式是有问题的，可能用了不适合的特征和思路来判断这个世界（**[模型结构](https://www.zhihu.com/search?q=%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2021534291%7D)本身的偏差**）。
  - 模型学习到的数据分布只是局部的，和真实的数据分布仍然有差距，这种偏差叫做 Inductive Bias。
  - [如何理解Inductive bias？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/264264203)
