# Neural Classifiers

## Intro

本节课的目标：

1. 学会接触单词的词义
2. 学习神经网络分类器的概念
3. 能够顺场地看一些 word embedding 的论文，例如 Google word2vec 论文、GLoVe 论文等

上节课我们建立了如何构建 word vector 的模型，并且推导出如何求解和优化词向量模型，但这只是最简单的算法，这个算法能够比较好的学习单词之间的相似性和词义的方向，更好地预测周围的单词。

:::info Bag of Word Model

Bag of Word，也就是 NLP 当中的词袋模型。其实我们的词向量本质上也是一种词袋模型，他不会关注单词所在的位置或者顺序，预测的概率是相同的。但这种模型也是非常粗糙的，不够精细。  

:::

word2vec 其实是将意思相近的单词在高维的向量空间当中彼此靠近，将相似的单词分组。
