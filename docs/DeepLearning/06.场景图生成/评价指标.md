# SGG 中一些常见的评价指标

### Recall@K (R@K)

这是早期在场景图生成领域中最为广泛能接受的指标，早期是在 [Visual relationship detection with language priors](https://arxiv.org/abs/1608.00187) 论文当中被首次使用。因为当时 GT 的关系标签不是很完善，导致错误地使用这个指标来作为关系分类准确度的指标。因此，Lu et al. 将 SGG 转换为一个类似图像检索的问题。

:::info

关系不仅仅是要分类正确，而且需要尽可能达到更高的准确度，以便于找到正确的关系，剔除掉没有关系的物体对。

:::

Recall@K 主要是计算谓词分类正确的准确度，只要谓词分类正确，就会被当作正样本，计算公式为：
$$
Recall=\frac{TP}{TP+FN}
$$
其中，TP 表示 true positive 意思为正样本，FN 表示 false negative 意思为负样本。

### Mean Recall@K (mR@K)

这个指标是 VCTree 这篇工作和 Chen 等人所做的 KERN 这篇工作同时提出的。虽然这不是我们最主要的贡献。只在补充材料中完整展示了结果。由于 Visual Genome 数据集的长尾效应，传统 Recall 往往只要学会几个主要的 relation 类比如 on，near 等，即便完全忽视大部分类别也可以取得很好的结果。这当然不是我们想看到的，所以 mean Recall 做了一件很简单的事，把所有谓语类别的 Recall 单独计算，然后求均值，这样所有类别就一样重要了。这样使得模型也能够尽可能从多个 relation（有大量简单 relation的重复）学会尽可能多种类的 relation。

### No Graph Constraint Recall@K (ngR@K)

这个指标最早由 [Pixel2Graph](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.07365) 使用，由 [Neural-MOTIFS](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1711.06640) 命名。这个指标的目的在于，传统的 Recall 计算里，一对物体只能有一个 relation 参与最终的排序，但 ngR@K 允许一对物体的所有 relation 都能参与排序。

这也非常有道理，比如有这样一个关系 `<human(0.9) - riding (0.6) - horse (0.9)>`，那么他的总得分就是 total score=0.9x0.6x0.9，但可能这对物体还有另一个 relation：`human(0.9) - on (0.3) - horse (0.9)`，那么他的总分是 total score=0.9x0.3x0.9。后者虽然分数比 riding 低，但也是一种可能的情况。ngR@K 的结果往往大大高于单纯的 R@K。

也就是说这个指标不单单考虑预测得分，更多还会关注 triplet 的合法性。即使存在有个别关系的得分比较低，但是这个关系依旧存在，那我们认为也是预测正确的。所以考虑了 subject, object 和 predicate 之间的约束关系。

### No Graph Constraint Mean Recall@K (ng-mR@K)

与 Mean Recall 指标相同，所有的谓词对于每一个物体对而言都有潜在可能的关系。（普通的 Mean recall 只考虑分数最高的 triplet 作为计算 Recall 的正样本）这个指标会把所有有效的谓词都作为计算的正样本。不受限于分数，从关系的角度来考虑。

### Zero Shot Recall@K (zR@K)

第一次在 VRD 数据集上的 [Visual relationship detection with language priors](https://arxiv.org/abs/1608.00187) 这篇工作中使用，也是第一次在 VG 数据集上的 [Unbiased Scene Graph Generation from Biased Training](https://arxiv.org/abs/2002.11949) 所使用。简单来说，这个指标只会计算 Recall@K 中训练集不存在的关系。也就是只会把模型预测出来的关系中，在训练集不存在的关系作为正样本来计算。

### No Graph Constraint Zero Shot Recall@K (ng-zR@K)

与 Zero-shot Recall 指标相同，所有的谓词对于每一个物体对而言都是潜在可能的关系。（原始的 Zero-shot Recall 只考虑分数最高的 triplet 作为计算 Recall 正样本）而这个指标则会把所有有效的谓词都作为计算的正样本。不受限于分数，从关系的角度来考虑。

### Top@K Accuracy (A@K)

这个指标来自于某个之前研究者对 PredCls 和 SGCls 的误解，并不建议大家 report 到文章中，这里列出来是希望大家以后别犯这个错。

该同学在 PredCls 和 SGCls 中不仅给了所有 object 的 bounding box，还给了主语-宾语所有 pair 的组合，所以这就完全不是一个 Recall 的检索了，而是给定两个物体，来判断他们 relation 的正确率。

### Sentence-to-Graph Retrieval (S2G)

最后是在 [Causal-TDE ](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2002.11949)中提出的 ground-truth caption 到 SG 检索，它可以看成一个理想的下游任务，可以看作一个 VQA：问指定图片的 SG 符不符合给定描述。他的意义在于，他完全摒弃了 visual feature，只使用符号化的 SG。他可以测试检测出的 SG 是否可以用来完整地丰富地表示原图（潜台词：从而支持符号化的推理）。由于这需要额外的训练过程，所以并不能直接在 SGG 的 val/test 里输出。

### @K 的意思

在上述说到的指标后面都会带有 `@K` 这个标志。`@K` 可以表示在一个预测出来的样本集合中，前 $k$ 个样本分类正确的数量。下面以 `mAP@K` 作例子。

#### mAP@K

$mAP$ (mean Average Precision) 表示平均的 $AP_i$ 分数， 相当于由多个 $AP_i$ 求均值之后得到。那 $mAP@K$ 可以由多个 $AP@K$ 得到，那 $AP@K$ 可由下面的计算公式得到：
$$
AP@K=\frac{1}{N(K)}\sum_{i=1}^k\frac{TP_{seen}(i)}{i}
$$
意思就是取前 $k$ 个正样本，然后对其求均值。其中 $N(K)$ 和 $TP$ 的计算方式如下：
$$
N(K)=\min(K,TP_{total}) \\ 
\begin{cases}
0;i^{th}\text{ is False} \\
\text{TP seen till i};i^{th}\text{ is True} \\
\end{cases}
$$
从这一步可以看出，所求均值的分母是 $K$ 或者是正样本的总数 $TP_{total}$，在他们之间取最小值。可以理解为，如果一个样本集当中，经过预测之后被判断为正样本的数量至多 $K$ 个里面，所计算得到的准确率。

最后对 $AP@K$ 求均值即可得到 $mAP@K$。
$$
mAP@K=\frac{1}{N}\sum_{i=1}^NAP@K_i
$$

## Reference

- [How mean Average Precision at k (mAP@k) can be more useful than other evaluation metrics | by Asher U. | Medium](https://medium.com/@misty.mok/how-mean-average-precision-at-k-map-k-can-be-more-useful-than-other-evaluation-metrics-6881e0ee21a9)
- [Scene-Graph-Benchmark.pytorch/METRICS.md at master · KaihuaTang/Scene-Graph-Benchmark.pytorch (github.com)](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch/blob/master/METRICS.md)
- [(CVPR 2020 Oral)最新Scene Graph Generation开源框架与一些碎碎念 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/109657521)

